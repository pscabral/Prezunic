{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNh3vcgv23faD1RkAqxEl4j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pscabral/Prezunic/blob/main/Untitled73.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz5fnpoqjqnx",
        "outputId": "17e2a7b5-3357-4b07-bca9-264ff0476753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GroceryStoreDataset'...\n",
            "remote: Enumerating objects: 6559, done.\u001b[K\n",
            "remote: Counting objects: 100% (266/266), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 6559 (delta 45), reused 35 (delta 35), pack-reused 6293\u001b[K\n",
            "Receiving objects: 100% (6559/6559), 116.26 MiB | 26.50 MiB/s, done.\n",
            "Resolving deltas: 100% (275/275), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/marcusklasson/GroceryStoreDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalação do TensorFlow (descomente a linha abaixo se o TensorFlow não estiver instalado)\n",
        "!pip install tensorflow\n",
        "\n",
        "# Importação de recursos futuros do Python para compatibilidade\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# Importação de bibliotecas\n",
        "import collections\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from six.moves import urllib\n",
        "import io\n",
        "import shutil\n",
        "\n",
        "# Importações para visualização no IPython\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "\n",
        "# Importações para aprendizado de máquina com TensorFlow e Keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Importações adicionais\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as sk_metrics\n",
        "import time\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "\n",
        "# Importações específicas para modelos de redes neurais\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras import regularizers\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, Flatten\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "r_LO34AxjxBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Caminho para o diretório de treinamento das imagens\n",
        "train_data_dir = '/content/GroceryStoreDataset/dataset/train/Fruit/'\n",
        "\n",
        "# Definir parâmetros para o pré-processamento das imagens\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Crie um gerador de dados para treinamento com aumento de dados\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2)  # Usar 20% dos dados para validação\n",
        "\n",
        "# Crie geradores de dados para treinamento e validação\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training')  # Use a porção de treinamento\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')  # Use a porção de validação\n",
        "\n",
        "# Inicialize o LabelEncoder e ajuste-o aos rótulos de classe do seu conjunto de treinamento\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_generator.classes)\n",
        "\n",
        "# Salvar as classes em um arquivo numpy\n",
        "np.save('/content/label_encoder_classes.npy', label_encoder.classes_)\n",
        "\n",
        "# Crie um modelo baseado na arquitetura InceptionV3 (você pode ajustar a arquitetura conforme necessário)\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "\n",
        "# Adicione camadas personalizadas para classificação\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)  # Usar o número de classes\n",
        "\n",
        "# Crie o modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile o modelo com learning_rate em vez de lr\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Defina callbacks para parar o treinamento prematuramente se a validação não melhorar\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# Treine o modelo\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=30,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size,\n",
        "    callbacks=[early_stopping])\n",
        "\n",
        "# Caminho para o diretório de teste das imagens\n",
        "test_data_dir = '/content/GroceryStoreDataset/dataset/test/Fruit/'\n",
        "\n",
        "# Crie um gerador de dados para teste\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Crie um gerador de dados de teste\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "eval_result = model.evaluate(test_generator)\n",
        "\n",
        "# Exiba a precisão no conjunto de teste\n",
        "print(f'Acurácia no conjunto de teste: {eval_result[1]*100:.2f}%')\n",
        "\n",
        "# Salve o modelo treinado\n",
        "model.save('classification_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef1syJeKj3Bw",
        "outputId": "e592b970-dbcd-403d-8876-f507cea9d751"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 920 images belonging to 19 classes.\n",
            "Found 222 images belonging to 19 classes.\n",
            "Epoch 1/30\n",
            "28/28 [==============================] - 471s 16s/step - loss: 1.6329 - accuracy: 0.5529 - val_loss: 2.9620 - val_accuracy: 0.4115\n",
            "Epoch 2/30\n",
            "28/28 [==============================] - 467s 17s/step - loss: 0.4213 - accuracy: 0.9054 - val_loss: 2.8769 - val_accuracy: 0.3958\n",
            "Epoch 3/30\n",
            "28/28 [==============================] - 468s 17s/step - loss: 0.1643 - accuracy: 0.9565 - val_loss: 1.5328 - val_accuracy: 0.6250\n",
            "Epoch 4/30\n",
            "28/28 [==============================] - 464s 17s/step - loss: 0.0621 - accuracy: 0.9842 - val_loss: 1.1232 - val_accuracy: 0.7135\n",
            "Epoch 5/30\n",
            "28/28 [==============================] - 465s 17s/step - loss: 0.0422 - accuracy: 0.9887 - val_loss: 0.2883 - val_accuracy: 0.9271\n",
            "Epoch 6/30\n",
            "28/28 [==============================] - 461s 16s/step - loss: 0.0383 - accuracy: 0.9932 - val_loss: 0.2066 - val_accuracy: 0.9271\n",
            "Epoch 7/30\n",
            "28/28 [==============================] - 447s 16s/step - loss: 0.0602 - accuracy: 0.9820 - val_loss: 0.2285 - val_accuracy: 0.9323\n",
            "Epoch 8/30\n",
            "28/28 [==============================] - 454s 16s/step - loss: 0.0206 - accuracy: 0.9921 - val_loss: 0.2645 - val_accuracy: 0.9323\n",
            "Epoch 9/30\n",
            "28/28 [==============================] - 447s 16s/step - loss: 0.0266 - accuracy: 0.9932 - val_loss: 0.2936 - val_accuracy: 0.9323\n",
            "Epoch 10/30\n",
            "28/28 [==============================] - 425s 15s/step - loss: 0.0355 - accuracy: 0.9932 - val_loss: 0.3713 - val_accuracy: 0.9271\n",
            "Epoch 11/30\n",
            "28/28 [==============================] - 444s 16s/step - loss: 0.0493 - accuracy: 0.9809 - val_loss: 0.3315 - val_accuracy: 0.9323\n",
            "Found 1117 images belonging to 19 classes.\n",
            "35/35 [==============================] - 121s 3s/step - loss: 1.8038 - accuracy: 0.6661\n",
            "Acurácia no conjunto de teste: 66.61%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}