{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNglSR2308tvLp/M5G0IMYo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pscabral/Prezunic/blob/main/Vgg19_v1_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpEg032TlAn_"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/PhilJd/freiburg_groceries_dataset.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd freiburg_groceries_dataset/src"
      ],
      "metadata": {
        "id": "tQ-JGEUFlapq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python download_dataset.py"
      ],
      "metadata": {
        "id": "lwrCr4P6lfcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras.applications.vgg19 import decode_predictions\n",
        "from keras.applications.vgg19 import VGG19\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load the model\n",
        "model = VGG19()\n",
        "\n",
        "# load an image from file\n",
        "image = load_img('/content/oleo.png', target_size=(224, 224))\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Remove os eixos (bordas) da imagem\n",
        "plt.show()\n",
        "\n",
        "# convert the image pixels to a numpy array\n",
        "image = img_to_array(image)\n",
        "\n",
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)\n",
        "\n",
        "# predict the probability across all output classes\n",
        "yhat = model.predict(image)\n",
        "\n",
        "# convert the probabilities to class labels\n",
        "label = decode_predictions(yhat)\n",
        "\n",
        "# retrieve the most likely result, e.g. highest probability\n",
        "label = label[0][0]\n",
        "\n",
        "# print the classification\n",
        "print('%s (%.2f%%)' % (label[1], label[2]*100))"
      ],
      "metadata": {
        "id": "G0KHoRWqlgjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Especificar o caminho para o diretório que contém as imagens\n",
        "diretorio_imagens = '/content/freiburg_groceries_dataset/images/CHOCOLATE'\n",
        "\n",
        "# Listar todos os arquivos no diretório de imagens\n",
        "imagens = os.listdir(diretorio_imagens)\n",
        "\n",
        "# Pré-processamento e carregamento das imagens\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for imagem_nome in imagens:\n",
        "    # Construir o caminho completo para a imagem\n",
        "    caminho_imagem = os.path.join(diretorio_imagens, imagem_nome)\n",
        "\n",
        "    img = Image.open(caminho_imagem)\n",
        "    img = img.resize((224, 224))  # Redimensionar para o tamanho esperado pela VGG19\n",
        "    img = np.array(img)\n",
        "    img = preprocess_input(img)  # Pré-processamento específico da VGG19\n",
        "\n",
        "    X.append(img)\n",
        "    y.append(imagem_nome)  # Nome da imagem como rótulo\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Codificar os rótulos em números\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Dividir o conjunto de dados em treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Carregar o modelo VGG19 pré-treinado com pesos do ImageNet\n",
        "base_model = VGG19(weights='imagenet', include_top=False)\n",
        "\n",
        "# Adicionar camadas personalizadas para a tarefa de classificação\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "# Criar o modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Congelar as camadas convolucionais para usar os pesos pré-treinados\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Avaliar o modelo no conjunto de teste\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(f'Acurácia no conjunto de teste: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "1J5qxnH0mF_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from google.colab.patches import cv2_imshow\n",
        "from gtts import gTTS\n",
        "import IPython.display as ipd\n",
        "\n",
        "# Caminho para a imagem de teste\n",
        "caminho_imagem_teste = '/content/TesteIMG/chocolate21.jpg'  # Substitua pelo caminho da sua imagem de teste\n",
        "\n",
        "# Ler a imagem de teste\n",
        "image = cv2.imread(caminho_imagem_teste)\n",
        "\n",
        "# Redimensionar a imagem para o tamanho esperado pela VGG19\n",
        "image_resized = cv2.resize(image, (224, 224))\n",
        "\n",
        "# Adicionar a dimensão do lote (batch)\n",
        "image_resized = np.expand_dims(image_resized, axis=0)\n",
        "\n",
        "# Pré-processamento específico da VGG19\n",
        "image_preprocessed = preprocess_input(image_resized)\n",
        "\n",
        "# Fazer a previsão usando o modelo treinado\n",
        "predicted_label = model.predict(image_preprocessed)\n",
        "\n",
        "# Descodificar o rótulo previsto de volta para o nome da classe\n",
        "predicted_class = label_encoder.inverse_transform([np.argmax(predicted_label)])[0]\n",
        "\n",
        "# Exibir a imagem com a previsão\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "cv2.putText(image, f'{predicted_class}', (10, 50), font, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "cv2_imshow(image)\n",
        "\n",
        "# Gerar o arquivo de áudio com o nome do produto previsto\n",
        "tts = gTTS(text=f'O produto é {predicted_class}', lang='pt')\n",
        "tts.save('/content/prevision.mp3')\n",
        "\n",
        "# Reproduzir o arquivo de áudio\n",
        "ipd.Audio('/content/prevision.mp3')"
      ],
      "metadata": {
        "id": "qokDd8_TOKN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt-get install libzbar0\n",
        "#!pip install pyzbar\n",
        "\n",
        "import cv2\n",
        "from pyzbar.pyzbar import decode\n",
        "\n",
        "def decode_qr_code(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    decoded_objects = decode(image)\n",
        "    return decoded_objects\n",
        "\n",
        "def detect_and_display_barcodes(camera_id=0, window_name='OpenCV Barcode'):\n",
        "    bd = cv2.barcode.BarcodeDetector()\n",
        "    cap = cv2.VideoCapture(camera_id)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        ret_bc, decoded_info, _, points = bd.detectAndDecode(frame)\n",
        "\n",
        "        if ret_bc:\n",
        "            frame = cv2.polylines(frame, points.astype(int), True, (0, 255, 0), 3)\n",
        "            for s, p in zip(decoded_info, points):\n",
        "                if s:\n",
        "                    print(s)\n",
        "                    frame = cv2.putText(frame, s, p[1].astype(int),\n",
        "                                        cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "        cv2.imshow(window_name, frame)\n",
        "\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = \"/content/CodigoBarrasIMG/03labeljoy-code-EAN13-1696292502532.png\"\n",
        "    decoded_objects = decode_qr_code(image_path)\n",
        "\n",
        "    for obj in decoded_objects:\n",
        "        print(f'Tipo: {obj.type}')\n",
        "        print(f'Dado: {obj.data}')\n",
        "\n",
        "    detect_and_display_barcodes()"
      ],
      "metadata": {
        "id": "wtwjy4EiytCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# Caminho da imagem\n",
        "caminho_da_imagem = '/content/TesteIMG/chocolate02.jpg'\n",
        "\n",
        "try:\n",
        "  # Imprime o caminho da imagem\n",
        "  print('Caminho da imagem: {}'.format(caminho_da_imagem))\n",
        "\n",
        "  # Exibe a imagem\n",
        "  display(Image(caminho_da_imagem))\n",
        "except Exception as err:\n",
        "  # Erros serão lançados se o arquivo de imagem não existir ou se houver outros problemas.\n",
        "  print('Erro ao exibir a imagem: {}'.format(str(err)))"
      ],
      "metadata": {
        "id": "s0fW1_-LUPY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from pyzbar.pyzbar import decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def capture_barcode():\n",
        "    js = Javascript('''\n",
        "    async function captureBarcode() {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg');\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "    display(js)\n",
        "    data = eval_js('captureBarcode()')\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    # Salvar a imagem temporariamente\n",
        "    with open('temp.jpg', 'wb') as f:\n",
        "        f.write(binary)\n",
        "\n",
        "    # Ler o código de barras na imagem\n",
        "    image = cv2.imread('temp.jpg', 0)\n",
        "    decoded_objects = decode(image)\n",
        "    if decoded_objects:\n",
        "        for obj in decoded_objects:\n",
        "            barcode_data = obj.data.decode('utf-8')\n",
        "            print('Código de barras lido:', barcode_data)\n",
        "    else:\n",
        "        print('Nenhum código de barras foi detectado.')\n",
        "\n",
        "    # Remover a imagem temporária\n",
        "    import os\n",
        "    os.remove('temp.jpg')\n",
        "\n",
        "capture_barcode()"
      ],
      "metadata": {
        "id": "621YrEtvXFDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pyzbar.pyzbar as pyzbar\n",
        "\n",
        "def capture_qrcode():\n",
        "    js = Javascript('''\n",
        "    async function captureQRCode() {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg');\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "    display(js)\n",
        "    data = eval_js('captureQRCode()')\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    # Salvar a imagem temporariamente\n",
        "    with open('temp.jpg', 'wb') as f:\n",
        "        f.write(binary)\n",
        "\n",
        "    # Ler o QR code na imagem\n",
        "    image = cv2.imread('temp.jpg', 0)\n",
        "    decoded_objects = pyzbar.decode(image)\n",
        "    if decoded_objects:\n",
        "        for obj in decoded_objects:\n",
        "            qr_data = obj.data.decode('utf-8')\n",
        "            print('QR Code lido:', qr_data)\n",
        "    else:\n",
        "        print('Nenhum QR Code foi detectado.')\n",
        "\n",
        "    # Remover a imagem temporária\n",
        "    import os\n",
        "    os.remove('temp.jpg')\n",
        "\n",
        "capture_qrcode()"
      ],
      "metadata": {
        "id": "vG38-Z-6d6qH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}